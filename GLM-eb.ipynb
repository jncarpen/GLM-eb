{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLM-eb /\n",
    "J. Carpenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import scipy.sparse as sps\n",
    "from pyglmnet import GLM, simulate_glm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & format data\n",
    "filepath = 'sampleData.mat'\n",
    "mat = scipy.io.loadmat(filepath)\n",
    "\n",
    "ST = mat['ST']; P = mat['P']; hd = mat['hd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class glm:\n",
    "    def __init__(self, ST, P, hd):\n",
    "        self.ST = ST\n",
    "        self.P = P\n",
    "        self.x = P[:,2]\n",
    "        self.y = P[:,3]\n",
    "        self.hd = (hd[:,0]*np.pi)/180; # 0-2pi\n",
    "        \n",
    "    def get_size(self):\n",
    "        boxsz = np.max([np.max(self.x), np.max(self.y)]);\n",
    "        return boxsz\n",
    "    \n",
    "    def pos_map(self, nbins=10):\n",
    "        boxsz = self.get_size()\n",
    "        bins = np.arange(boxsz/nbins/2, boxsz-boxsz/nbins/2, boxsz/nbins)\n",
    "        posgrid = np.zeros((len(self.x), nbins**2))\n",
    "        for idx,val in enumerate(self.x):\n",
    "            xvec = np.abs(self.x[idx]-bins); yvec = np.abs(self.y[idx]-bins);\n",
    "            min_x = np.min(xvec)\n",
    "            min_y = np.min(yvec)\n",
    "            idx_x = np.where(xvec == min_x); idx_x = idx_x[0][0];\n",
    "            idx_y = np.where(yvec == min_y); idx_y = idx_y[0][0];\n",
    "            bin_idx = np.ravel_multi_index((idx_y,idx_x), dims=(nbins,nbins), order='C') # a11=0, a12=1, a13=2;\n",
    "            posgrid[idx, bin_idx] = 1;\n",
    "        return posgrid, bins\n",
    "    \n",
    "    def eb_map(self, nbins=10, rp=[75,75]):\n",
    "        refx = rp[0]; refy = rp[1];\n",
    "        allo = np.arctan2(refy-self.y, refx-self.x) + (np.pi/2); # add 90 deg\n",
    "        allo[allo<0] = allo[allo<0]+2*np.pi;\n",
    "        ego = allo - self.hd; # shift from 0-2pi\n",
    "        egogrid = np.zeros((len(P),nbins));\n",
    "        bins = np.arange(2*np.pi/nbins/2, 2*np.pi-2*np.pi/nbins/2, 2*np.pi/nbins) # 10 bin ctrs\n",
    "        for idx,val in enumerate(P):\n",
    "            evec = np.abs(ego[idx]-bins)\n",
    "            min_e = np.min(evec)\n",
    "            idx_e = np.where(evec == min_e)\n",
    "            egogrid[idx, idx_e] = 1;\n",
    "        return egogrid, bins\n",
    "    \n",
    "    def conv_spktrain(self):\n",
    "        # filter the spiketrain\n",
    "        t = self.P[:,0];\n",
    "        boolean_spk = np.logical_and(t[0] <= self.ST, self.ST <= t[-1])\n",
    "        spikes = self.ST[boolean_spk == True]\n",
    "        edgesT = np.linspace(t[0], t[-1], len(t)+1)\n",
    "        binnedSpikes, timeEdges = np.histogram(spikes, edgesT)\n",
    "        # convolve w/ gaussian membership fn\n",
    "        Xx = np.linspace(-4,4,9); sigma = 2; c = 0;\n",
    "        filt = np.exp((-(Xx-c)**2)/(2*(sigma**2)))\n",
    "        dt = self.P[1,0]-self.P[0,0];\n",
    "        fr = binnedSpikes/dt # rate (hz)\n",
    "        smooth_fr = np.convolve(binnedSpikes, filt, mode='full')\n",
    "        return smooth_fr\n",
    "    \n",
    "    def get_speed(self):\n",
    "        t=self.P[:,0]; x=self.P[:,1]; y=self.P[:,2];\n",
    "        ntime = len(t); v = np.zeros((ntime,1));\n",
    "        for idx in range(1,ntime-1):\n",
    "            v[idx,0] = np.sqrt((x[idx+1]-x[idx-1])**2 + (y[idx+1]-y[idx-1])**2)/(t[idx+1]-t[idx-1])    \n",
    "        v[0,0] = v[1,0]; v[-1,0] = v[-2,0] # pad the array\n",
    "        return v\n",
    "    \n",
    "    def speed_threshold(self,posgrid,ebgrid,spiketrain):\n",
    "        v = self.get_speed()\n",
    "        maxspeed=50; minspeed=4\n",
    "        inbounds = np.logical_and((v<=maxspeed), (v>=minspeed))\n",
    "        inbounds = np.where(inbounds==True); inbounds = inbounds[0]\n",
    "        posgrid = posgrid[inbounds,:]\n",
    "        ebgrid = ebgrid[inbounds,:]\n",
    "        spiketrain = spiketrain[inbounds]\n",
    "        return posgrid, ebgrid, spiketrain\n",
    "    \n",
    "    def squish_statemat(self,posgrid,ebgrid):\n",
    "        '''squish state matrix for 2-variable model (P+EB)'''\n",
    "        ntime,nbins_eb = np.shape(ebgrid)\n",
    "        _,nbins_p = np.shape(posgrid)\n",
    "        A = np.zeros((ntime, nbins_p+nbins_eb)) #P+EB\n",
    "        A[:,0:nbins_p] = posgrid; A[:,nbins_p:] = ebgrid\n",
    "        df=pd.DataFrame(A)\n",
    "        mask = np.random.rand(len(df)) < 0.8\n",
    "        df_train = df[mask]; df_test = df[~mask]\n",
    "        # name columns & get expression\n",
    "        colnames = [];\n",
    "        expr = 'y ~ '\n",
    "        for i in range(nbins_p):\n",
    "            val = str(i);\n",
    "            expr = expr + 'P' + val + ' + '\n",
    "            colnames.append('P' + val)\n",
    "        for i in range(nbins_eb-1):\n",
    "            val = str(i);\n",
    "            expr = expr + 'E' + val + ' + '\n",
    "            colnames.append('E' + val)\n",
    "        expr = expr + 'E9'\n",
    "        colnames.append('E9')\n",
    "        df.columns = colnames\n",
    "        return df,expr\n",
    "    \n",
    "    def test_train(self,df,expr,spiketrain):\n",
    "        df.insert(loc=0, column='y', value=spiketrain, allow_duplicates=False)\n",
    "        mask = np.random.rand(len(df)) < 0.8\n",
    "        df_train = df[mask]\n",
    "        df_test = df[~mask]\n",
    "        # split into test and train\n",
    "        y_train, X_train = dmatrices(expr, df_train, return_type='dataframe')\n",
    "        y_test, X_test = dmatrices(expr, df_test, return_type='dataframe')\n",
    "        # info for user\n",
    "        print('Training data set length='+str(len(df_train)))\n",
    "        print('Testing data set length='+str(len(df_test)))\n",
    "        return y_train, X_train, y_test, X_test\n",
    "    \n",
    "    def test_train_arr(self,df,expr,spiketrain):\n",
    "        '''return training set as array (not df)'''\n",
    "        y_train, X_train, y_test, X_test = self.test_train(df,expr,spiketrain)\n",
    "        y_train = y_train.to_numpy(); y_test = y_test.to_numpy()\n",
    "        X_test = X_test.to_numpy(); X_train = X_train.to_numpy()\n",
    "        X_train = X_train[:,1:];  X_test = X_test[:,1:]\n",
    "        return y_train, X_train, y_test, X_test\n",
    "    \n",
    "    def init_params(self,whichVars={'P', 'E'}):\n",
    "        if whichVars == {'P', 'E'}: init_param = 1e-3*np.random.randn(110, 1);\n",
    "        if whichVars == {'P'}: init_param = 1e-3*np.random.randn(100, 1);\n",
    "        if whichVars == {'E'}: init_param = 1e-3*np.random.randn(10, 1);\n",
    "        return init_param\n",
    "    \n",
    "    def get_rate(self,x,w,b):\n",
    "        '''conditional intensity function'''\n",
    "        y_hat = np.exp(x @ w + b)\n",
    "        return y_hat\n",
    "\n",
    "    def loss(self,x, y, w, b):\n",
    "        '''objective function'''\n",
    "        y_hat = np.exp(x @ w + b)\n",
    "        # You can use the normal MSE error too! \n",
    "        #error = np.square(y_hat - y).mean() / 2\n",
    "        error = (y_hat - np.log(y_hat) * y).mean()\n",
    "        return error\n",
    "    \n",
    "    def grad(self,x, y, w, b):\n",
    "        M, n = x.shape\n",
    "        y_hat = np.exp(x @ w + b)\n",
    "        dw = (x.T @ (y_hat - y)) / M\n",
    "        db = (y_hat - y).mean()\n",
    "        return dw, db\n",
    "\n",
    "    def gradient_descent(self,x, y, w_0, b_0, alpha, num_iter):\n",
    "        w, b = w_0.copy(), b_0\n",
    "        hist = np.zeros(num_iter)\n",
    "        M, n = x.shape\n",
    "\n",
    "        for iter in range(num_iter):\n",
    "            dw, db = self.grad(x, y, w, b)\n",
    "            w -= alpha * dw \n",
    "            b -= alpha * db\n",
    "            hist[iter] = self.loss(x, y, w, b)\n",
    "\n",
    "        return w, b, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set length=39069\n",
      "Testing data set length=9721\n"
     ]
    }
   ],
   "source": [
    "# initialize class instance\n",
    "g = glm(ST,P,hd)\n",
    "\n",
    "# prepare the data\n",
    "posgrid_raw,bins = g.pos_map(nbins=10)\n",
    "ebgrid_raw,bins = g.eb_map(nbins=10, rp=[75,75])\n",
    "smooth_fr = g.conv_spktrain()\n",
    "posgrid,ebgrid,spiketrain = g.speed_threshold(posgrid_raw,ebgrid_raw,smooth_fr)\n",
    "df,expr = g.squish_statemat(posgrid,ebgrid)\n",
    "\n",
    "# split data into test/train\n",
    "y_train, X_train, y_test, X_test = g.test_train_arr(df,expr,spiketrain)\n",
    "\n",
    "# get initial parameters (beta0 and beta_i's)\n",
    "M,n = np.shape(X)\n",
    "w_0 = np.zeros((n, )) # initial params\n",
    "b_0 = 1\n",
    "alpha = 0.001\n",
    "X = X_train; y = y_train;\n",
    "w, b, hist = g.gradient_descent(X, y, w_0, b_0, alpha, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
