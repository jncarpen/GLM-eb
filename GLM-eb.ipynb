{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM-eb \n",
    "@author: Jordan, Ben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preamble\n",
    "import scipy.io\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import scipy.sparse as sps\n",
    "import scipy.stats as stats\n",
    "from pyglmnet import GLM, simulate_glm\n",
    "import scipy as sp\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization parameters\n",
    "plt.rcParams['figure.figsize'] = (10,4)\n",
    "plt.rc('axes', labelsize=12); plt.rc('axes', titlesize=14)\n",
    "plt.style.use('ggplot'); plt.rc('font', size=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & format data\n",
    "filepath = 'sampleData.mat'\n",
    "mat = scipy.io.loadmat(filepath)\n",
    "ST = mat['ST']; P = mat['P']; hd = mat['hd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class glm:\n",
    "    def __init__(self, ST, P, hd):\n",
    "        self.ST = ST\n",
    "        self.P = P\n",
    "        self.x = P[:,1]\n",
    "        self.y = P[:,2]\n",
    "        self.t = P[:,0]\n",
    "        self.hd = (hd[:,0]*np.pi)/180; # 0-2pi\n",
    "        self.dt = np.round(statistics.mode(np.diff(P[:,0])),2);\n",
    "        \n",
    "    def get_size(self):\n",
    "        '''get size of recording box'''\n",
    "        boxsz = np.max([np.max(self.x), np.max(self.y)]);\n",
    "        return boxsz\n",
    "    \n",
    "    def pos_map(self, nbins=10):\n",
    "        '''design matrix for position variables'''\n",
    "        boxsz = self.get_size()\n",
    "        bins = np.arange(boxsz/nbins/2, boxsz-boxsz/nbins/2, boxsz/nbins)\n",
    "        posgrid = np.zeros((len(self.x), nbins**2))\n",
    "        for idx,val in enumerate(self.x):\n",
    "            xvec = np.abs(self.x[idx]-bins); yvec = np.abs(self.y[idx]-bins);\n",
    "            min_x = np.min(xvec)\n",
    "            min_y = np.min(yvec)\n",
    "            idx_x = np.where(xvec == min_x); idx_x = idx_x[0][0];\n",
    "            idx_y = np.where(yvec == min_y); idx_y = idx_y[0][0];\n",
    "            bin_idx = np.ravel_multi_index((idx_y,idx_x), dims=(nbins,nbins), order='C') # a11=0, a12=1, a13=2;\n",
    "            posgrid[idx, bin_idx] = 1;\n",
    "        return posgrid, bins\n",
    "    \n",
    "    def eb_map(self, nbins=10, rp=[75,75]):\n",
    "        '''design matrix for egocentric variables'''\n",
    "        refx = rp[0]; refy = rp[1];\n",
    "        allo = np.arctan2(refy-self.y, refx-self.x) + (np.pi/2); # add 90 deg\n",
    "        allo[allo<0] = allo[allo<0]+2*np.pi;\n",
    "        ego = allo - self.hd; # shift from 0-2pi\n",
    "        egogrid = np.zeros((len(P),nbins));\n",
    "        bins = np.arange(2*np.pi/nbins/2, 2*np.pi-2*np.pi/nbins/2, 2*np.pi/nbins) # 10 bin ctrs\n",
    "        for idx,val in enumerate(P):\n",
    "            evec = np.abs(ego[idx]-bins)\n",
    "            min_e = np.min(evec)\n",
    "            idx_e = np.where(evec == min_e)\n",
    "            egogrid[idx, idx_e] = 1;\n",
    "        return egogrid, bins\n",
    "    \n",
    "    def conv_spktrain(self, Xx=np.linspace(-4,4,9),\n",
    "                      sigma=2,c=0,defaultST=True,spikeIn=[1,2,3],dt=0.02):\n",
    "        '''get smoothed spiketrain from spiketimes\n",
    "            **kwargs:\n",
    "            spikeTrain- 'False' if user wants self.ST (spiketimes)\n",
    "                        'True' if user wants to use a pre-allocated spiketrain\n",
    "            spikeIn-    use this optional kwarg iff spikeTrain==True\n",
    "        '''\n",
    "        if defaultST==True:\n",
    "            t = self.P[:,0]; dt = self.P[1,0]-self.P[0,0]; # time per frame\n",
    "            boolean_spk = np.logical_and(t[0] <= self.ST, self.ST <= t[-1])\n",
    "            spikes = self.ST[boolean_spk == True]\n",
    "            edgesT = np.linspace(t[0], t[-1], len(t)+1)\n",
    "            binnedSpikes, timeEdges = np.histogram(spikes, edgesT)\n",
    "            \n",
    "        elif defaultST==False:\n",
    "            binnedSpikes = spikeIn\n",
    "            \n",
    "        # convolve w/ gaussian membership function\n",
    "        filt = np.exp((-(Xx-c)**2)/(2*(sigma**2)))\n",
    "        fr = binnedSpikes/dt # rate (hz)\n",
    "        smooth_fr = np.convolve(binnedSpikes, filt, mode='same')\n",
    "        \n",
    "        return smooth_fr, binnedSpikes, filt, dt\n",
    "\n",
    "    \n",
    "    def get_speed(self):\n",
    "        '''get speed of the animal (cm*s^-2)'''\n",
    "        t=self.P[:,0]; x=self.P[:,1]; y=self.P[:,2];\n",
    "        ntime = len(t); v = np.zeros((ntime,1));\n",
    "        \n",
    "        for idx in range(1,ntime-1):\n",
    "            v[idx,0] = np.sqrt((x[idx+1]-x[idx-1])**2 + (y[idx+1]-y[idx-1])**2)/(t[idx+1]-t[idx-1])    \n",
    "        v[0,0] = v[1,0]; v[-1,0] = v[-2,0] # pad the array\n",
    "        \n",
    "        return v\n",
    "    \n",
    "    def speed_threshold(self,posgrid,ebgrid,spiketrain):\n",
    "        v = self.get_speed()\n",
    "        maxspeed=50; minspeed=4\n",
    "        inbounds = np.logical_and((v<=maxspeed), (v>=minspeed))\n",
    "        inbounds = np.where(inbounds==True); inbounds = inbounds[0]\n",
    "        posgrid = posgrid[inbounds,:]\n",
    "        ebgrid = ebgrid[inbounds,:]\n",
    "        spiketrain = spiketrain[inbounds]\n",
    "        return posgrid, ebgrid, spiketrain\n",
    "    \n",
    "    def squish_statemat(self, spiketrain, stateIn, modelType='PE'):\n",
    "        '''squish state matrix for 2-variable model (P+EB)\n",
    "            inputs- spiketrain is the speed-thresholded spiketrain'''\n",
    "        if modelType == 'PE':\n",
    "            posgrid = stateIn[0]; ebgrid = stateIn[1]\n",
    "            ntime,nbins_eb = np.shape(ebgrid)\n",
    "            _,nbins_p = np.shape(posgrid)\n",
    "            A = np.zeros((ntime, nbins_p+nbins_eb)) #P+EB\n",
    "            A[:,0:nbins_p] = posgrid; A[:,nbins_p:] = ebgrid\n",
    "            df=pd.DataFrame(A)\n",
    "            # name columns & get expression\n",
    "            colnames = [];\n",
    "            expr = 'y ~ '\n",
    "            for i in range(nbins_p):\n",
    "                val = str(i);\n",
    "                expr = expr + 'P' + val + ' + '\n",
    "                colnames.append('P' + val)\n",
    "            for i in range(nbins_eb-1):\n",
    "                val = str(i);\n",
    "                expr = expr + 'E' + val + ' + '\n",
    "                colnames.append('E' + val)\n",
    "            expr = expr + 'E9'\n",
    "            colnames.append('E9')\n",
    "            df.columns = colnames\n",
    "        elif modelType == 'P':\n",
    "            ntime,nbins = np.shape(stateIn)\n",
    "            df = pd.DataFrame(stateIn)\n",
    "            colnames = [];\n",
    "            expr = 'y ~ '\n",
    "            for i in range(nbins-1):\n",
    "                val = str(i);\n",
    "                expr = expr + 'P' + val + ' + '\n",
    "                colnames.append('P' + val)\n",
    "            expr = expr + 'P99'\n",
    "            colnames.append('P99')\n",
    "            df.columns = colnames\n",
    "        elif modelType == 'E':\n",
    "            ntime,nbins = np.shape(stateIn)\n",
    "            df = pd.DataFrame(stateIn)\n",
    "            colnames = [];\n",
    "            expr = 'y ~ '\n",
    "            for i in range(nbins-1):\n",
    "                val = str(i);\n",
    "                expr = expr + 'E' + val + ' + '\n",
    "                colnames.append('E' + val)\n",
    "            expr = expr + 'E9'\n",
    "            colnames.append('E9')\n",
    "            df.columns = colnames\n",
    "        else:\n",
    "            print('Error: model type must be \"P\", \"E\", or \"PE\"')\n",
    "        # if you want to do a 20-80 test-train split\n",
    "        # note: make this an option\n",
    "        mask = np.random.rand(len(df)) < 0.8\n",
    "        df_train = df[mask]; df_test = df[~mask]\n",
    "        # insert [raw] spiketrain into dataframe\n",
    "        df.insert(0, 'y', spiketrain)\n",
    "        return df,expr\n",
    "    \n",
    "    def kfoldSplit(self,nfolds=10):\n",
    "        '''train-test split for k-fold xval\n",
    "            each section is ~1 min'''\n",
    "        _, spiketrain, _, dt = self.conv_spktrain()\n",
    "        # calculate number of chunks given session length\n",
    "        nmins = (len(spiketrain)*dt)/60\n",
    "        nchunks = int(round(nmins/nfolds))\n",
    "        nsections = int(nchunks*nfolds)\n",
    "        # grab indices for k-fold splitting\n",
    "        kfoldIdx = {}\n",
    "        howLong = np.zeros(nfolds)\n",
    "        edges = np.round(np.linspace(1,len(spiketrain)+1,nsections+1))\n",
    "        for k in range(nfolds):\n",
    "            test_ind = np.floor(np.linspace(int(edges[k]),\n",
    "                    (int(edges[k+1])-1),\n",
    "                    (int(edges[k+1])-1)-int(edges[k])))\n",
    "            for s in range(1,nchunks):\n",
    "                ind = np.floor(np.linspace(int(edges[k+s*nfolds]),\n",
    "                                  (int(edges[k+s*nfolds+1])-1),\n",
    "                                  (int(edges[k+s*nfolds+1]))-int(edges[k+s*nfolds])))\n",
    "                test_ind = np.append(test_ind,ind)\n",
    "            kfoldIdx[k] = test_ind\n",
    "            howLong[k] = len(test_ind); del test_ind;\n",
    "        minArrLen = int(np.min(howLong));\n",
    "        for k in range(nfolds):\n",
    "            kfoldIdx[k] = kfoldIdx[k][0:minArrLen] # adjust arr. len (w/in .02 s)\n",
    "        kfoldIdx_df = pd.DataFrame.from_dict(kfoldIdx)\n",
    "        kfoldIdx_df = kfoldIdx_df.astype(int) # for idxing purposes\n",
    "        return kfoldIdx, kfoldIdx_df\n",
    "    \n",
    "    def kfoldOptim(self,kfoldIdx_df,statemat):\n",
    "        '''kfoldIdx_df can be retrieved from self.kfoldSplit()'''\n",
    "        \n",
    "        # intialize output structures\n",
    "        _,nfolds=np.shape(kfoldIdx_df); k_vec = np.arange(nfolds)\n",
    "        kres = {}; train_y = {}; train_x = {}; test_y = {}\n",
    "        test_x = {}; train_y_raw = {}; test_y_raw = {}\n",
    "        \n",
    "        for foldnum in range(nfolds):\n",
    "            k_vec_train = np.delete(k_vec, np.where(k_vec == foldnum))\n",
    "            idx_test = kfoldIdx_df.loc[:,foldnum].to_numpy()\n",
    "            idx_train = []\n",
    "            \n",
    "            # squeeze other nfolds-1 folds into one vector\n",
    "            for i,v in enumerate(k_vec_train):\n",
    "                nextRow = kfoldIdx_df.loc[:,v].to_numpy()\n",
    "                idx_train = np.append(idx_train,nextRow) \n",
    "            idx_train = idx_train.astype(int)\n",
    "            \n",
    "            # train-test statemats\n",
    "            df_test = statemat.loc[idx_test,:].dropna()\n",
    "            df_train = statemat.loc[idx_train,:].dropna()\n",
    "            y_test_raw = df_test['y'].to_numpy(dtype='int64');\n",
    "            y_train_raw = df_train['y'].to_numpy(dtype='int64')\n",
    "            \n",
    "            # smooth firing rates\n",
    "            y_test, _, _, _ = g.conv_spktrain(defaultST=False,spikeIn=y_test_raw)\n",
    "            y_train, _, _, _ = g.conv_spktrain(defaultST=False,spikeIn=y_train_raw) \n",
    "            \n",
    "            # put smoothed firing rates back into dataframe\n",
    "            df_test[df_test.columns[0]] = y_test; \n",
    "            df_train[df_train.columns[0]] = y_train\n",
    "            \n",
    "            # test/train arrays\n",
    "            X_test = df_test[df_test.columns[1:]].to_numpy(); y_test = df_test[df_test.columns[0]].to_numpy()\n",
    "            X_train = df_train[df_train.columns[1:]].to_numpy(); y_train = df_train[df_train.columns[0]].to_numpy()\n",
    "            \n",
    "            # set some initial parameters\n",
    "            M,n = np.shape(X_train)\n",
    "            w_0 = 1e-3*np.ones((n, ))\n",
    "            b_0 = 1\n",
    "            # alpha = 0.001 (can't remember when we use this)\n",
    "            \n",
    "            # get parameters & jacobian (1st order derivatives of loss fn)\n",
    "            data,param = self.getDataParam(X_train,y_train,w_0,b_0);\n",
    "            jac = self.grad(param,X_train,y_train)\n",
    "            \n",
    "            # optimize loss function\n",
    "            res = self.bfgs(data,param)\n",
    "            \n",
    "            # package outputs for each fold\n",
    "            kres[foldnum] = res\n",
    "            train_y[foldnum] = y_train; test_y[foldnum] = y_test\n",
    "            train_x[foldnum] = X_train; test_x[foldnum] = X_test\n",
    "            train_y_raw[foldnum] = y_train_raw; \n",
    "            test_y_raw[foldnum] = y_test_raw; \n",
    "            \n",
    "            del y_test_raw, y_train_raw # for debugging\n",
    "        return kres,train_y, test_y, train_x, test_x, train_y_raw, test_y_raw\n",
    "    \n",
    "    def init_params(self,whichVars={'P', 'E'}):\n",
    "        if whichVars == {'P', 'E'}: init_param = 1e-3*np.random.randn(110, 1);\n",
    "        if whichVars == {'P'}: init_param = 1e-3*np.random.randn(100, 1);\n",
    "        if whichVars == {'E'}: init_param = 1e-3*np.random.randn(10, 1);\n",
    "        return init_param\n",
    "    \n",
    "    def getDataParam(self,x,y,w,b):\n",
    "        '''put param & data in a dictionary'''\n",
    "        param = np.append(b,w)\n",
    "        data =  (x, y)\n",
    "        return data,param\n",
    "    \n",
    "    def get_rate(self,x,w,b):\n",
    "        '''conditional intensity function'''\n",
    "        # note: not normalized by dt (not in Hz)\n",
    "        y_hat = np.exp(x @ w + b)\n",
    "        return y_hat\n",
    "    \n",
    "    def loss(self,param,x,y):\n",
    "        '''objective function'''\n",
    "        \n",
    "        y_hat = np.exp(x @ param[1:] + param[0])\n",
    "        #negative log likelihood for possion where yhat is lambda\n",
    "        error = (y_hat - np.log(y_hat) * y).mean()\n",
    "        \n",
    "        return error\n",
    "    \n",
    "    def grad(self,param,x,y):\n",
    "        '''compute the gradient of the loss fn'''\n",
    "        M, n = x.shape\n",
    "        y_hat = np.exp(x @ param[1:] + param[0])\n",
    "        dw = (x.T @ (y_hat - y)) / M\n",
    "        db = (y_hat - y).mean() \n",
    "        # we dont really need [db] if the bias term is included as a column of 1's\n",
    "        # which right now it is currently NOT\n",
    "        jac = dw; jac=np.append(jac,db);\n",
    "        return jac\n",
    "\n",
    "    def gradient_descent(self,x, y, w_0, b_0, alpha, num_iter):\n",
    "        '''minimize loss function w/ gradient descent'''\n",
    "        w, b = w_0.copy(), b_0\n",
    "        hist = np.zeros(num_iter)\n",
    "        M, n = x.shape\n",
    "        for iter in range(num_iter):\n",
    "            dw, db = self.grad(x, y, w, b)\n",
    "            w -= alpha * dw\n",
    "            b -= alpha * db\n",
    "            hist[iter] = self.loss(x, y, w, b)\n",
    "        return w, b, hist\n",
    "    \n",
    "    def bfgs(self,data,param):\n",
    "        'minimize loss function w/ L-BFGS-B'\n",
    "        res = sp.optimize.minimize(self.loss, x0=param, args=data, method='L-BFGS-B', jac=self.grad)\n",
    "        # options={'gtol': 1e-6, 'disp': True})\n",
    "        return res\n",
    "    \n",
    "    def get_stats(self, y, y_hat):\n",
    "        # compare between test fr and model fr\n",
    "        sse = np.sum((y_hat-y)**2);\n",
    "        sst = sum((y-np.mean(y))**2);\n",
    "        varExplain_test = 1-(sse/sst)\n",
    "        r, pval_r = stats.pearsonr(y,y_hat)\n",
    "        return sse, sst, varExplain_test, r, pval_r\n",
    "    \n",
    "    def get_testFit(self,kres,train_y,test_y,train_x,test_x,train_y_raw,test_y_raw):\n",
    "        '''get statistics for model fit'''\n",
    "        # initialize output structures\n",
    "        yhatDict={}\n",
    "        nfolds=len(kres);\n",
    "        sse=np.zeros(nfolds); sst=np.zeros(nfolds)\n",
    "        varExplain_test=np.zeros(nfolds); pearson_r=np.zeros(nfolds)\n",
    "        pearson_pval=np.zeros(nfolds); funval=np.zeros(nfolds)\n",
    "        llh=np.zeros(nfolds)\n",
    "        \n",
    "        for fold in range(nfolds):\n",
    "            # predict model output on *test* data\n",
    "            yhat_raw = g.get_rate(test_x[fold],kres[fold].x[1:],kres[fold].x[0]) # not normalized\n",
    "            yhat, _, _, _ = g.conv_spktrain(defaultST=False,spikeIn=yhat_raw) # normalized by dt (hz)\n",
    "            \n",
    "            # compare between test and model rates\n",
    "            sse[fold] = np.sum((yhat-test_y[fold])**2); #sse\n",
    "            sst[fold]= sum((test_y[fold]-np.mean(test_y[fold]))**2); #sst\n",
    "            varExplain_test[fold] = 1-(sse[fold]/sst[fold]) #varExplained_test\n",
    "            pearson_r[fold],pearson_pval[fold] = stats.pearsonr(test_y[fold],yhat) #pearsonsR,p-val\n",
    "            funval[fold] = kres[fold].fun\n",
    "            yhatDict[fold] = yhat\n",
    "            \n",
    "            #compute llh increase from \"mean firing rate model\"\n",
    "            # NO SMOOTHING is used here\n",
    "            bestp = kres[fold]['x'] # best parameters\n",
    "            n = test_y_raw[fold]\n",
    "            arrFactorial = np.vectorize(math.factorial) # array-wise factorial fn\n",
    "            meanFR_test = np.nanmean(n)\n",
    "\n",
    "            # format the state matrix\n",
    "            b = np.ones((len(test_x[fold]),len(bestp)))\n",
    "            b[:,1:] = test_x[fold]\n",
    "            # get rate of 'mean fr model'\n",
    "            r = np.exp(b@bestp) # predicted rate (not normalized by dt)\n",
    "            \n",
    "            # compute log-likelihood value for the test data\n",
    "            log_llh_test_model = np.nansum(r-n*np.log(r)+np.log(arrFactorial(n)))/np.sum(n);\n",
    "            log_llh_test_mean = np.nansum(meanFR_test-n*np.log(meanFR_test)+np.log(arrFactorial(n)))/np.sum(n);\n",
    "            log_llh_test = (-log_llh_test_model + log_llh_test_mean);\n",
    "            log_llh_test = np.log(2)*log_llh_test;\n",
    "            llh[fold] = log_llh_test\n",
    "            \n",
    "            # akaike info criterion\n",
    "            # log is undefined b/c llh is negative\n",
    "            # AIC = 2*(len(bestp))-2*np.log(log_llh_test);\n",
    "            \n",
    "        # dictionary of statistics describing fit of test data to model\n",
    "        testfit = {\n",
    "            'llh_test': llh,\n",
    "            'sse': sse,\n",
    "            'sst': sst,\n",
    "            'varEx': varExplain_test,\n",
    "            'pearson_r': pearson_r,\n",
    "            'pearson_pval': pearson_pval,\n",
    "            'funval': funval,\n",
    "            'yhat': yhatDict\n",
    "        }\n",
    "        return testfit\n",
    "    \n",
    "    def findBestModel(self,modelDict):\n",
    "        '''modelDict is defined in the script below (incorporate)'''\n",
    "        numModels = len(allModels)\n",
    "        llh = np.zeros(numModels)\n",
    "        for model in range(numModels):\n",
    "            T = allModels[model]['testfit']\n",
    "            llh[model] = np.nanmean(T['llh_test'])\n",
    "        bestModel=np.where(llh==np.max(llh))[0][0]\n",
    "        print('best model: ' + labelDict[bestModel])\n",
    "        \n",
    "        return llh, bestModel\n",
    "    \n",
    "    def plot_llh(self,allModels):\n",
    "        # plot log-likelihood values for each model\n",
    "        numModels = len(allModels)\n",
    "        nfolds = len(allModels[0]['kres'].keys())\n",
    "        \n",
    "        llh = {}; whichModel = {}\n",
    "        for model in range(numModels):\n",
    "            a = allModels[model]['testfit']['llh_test']\n",
    "            a = a[None].T\n",
    "            llh[model] = a\n",
    "            whichModel[model] = np.ones((nfolds,1))*model\n",
    "\n",
    "        llh = np.vstack((llh[0], llh[1], llh[2]))\n",
    "        whichModel = np.vstack((whichModel[0], whichModel[1], whichModel[2]))\n",
    "        df = pd.DataFrame(np.hstack((llh,whichModel)), columns = ['llh','whichModel'])\n",
    "        ax = sns.swarmplot(x=\"whichModel\", y=\"llh\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### execute glm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17145\\.conda\\envs\\tdt4195\\lib\\site-packages\\ipykernel_launcher.py:264: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\17145\\.conda\\envs\\tdt4195\\lib\\site-packages\\ipykernel_launcher.py:264: RuntimeWarning: invalid value encountered in multiply\n",
      "C:\\Users\\17145\\.conda\\envs\\tdt4195\\lib\\site-packages\\ipykernel_launcher.py:262: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\17145\\.conda\\envs\\tdt4195\\lib\\site-packages\\ipykernel_launcher.py:271: RuntimeWarning: overflow encountered in exp\n",
      "C:\\Users\\17145\\.conda\\envs\\tdt4195\\lib\\site-packages\\ipykernel_launcher.py:272: RuntimeWarning: invalid value encountered in matmul\n",
      "C:\\Users\\17145\\.conda\\envs\\tdt4195\\lib\\site-packages\\ipykernel_launcher.py:264: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model: E\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize class instance\n",
    "g = glm(ST,P,hd)\n",
    "\n",
    "# prepare the data\n",
    "posgrid_raw,bins = g.pos_map(nbins=10)\n",
    "ebgrid_raw,bins = g.eb_map(nbins=10, rp=[75,75])\n",
    "smooth_fr, raw_spktrn, filt, dt = g.conv_spktrain() # get spiketrain\n",
    "posgrid,ebgrid,spiketrain = g.speed_threshold(posgrid_raw,ebgrid_raw,raw_spktrn)\n",
    "\n",
    "# dictionaries with info about each model\n",
    "stateDict = {\n",
    "    0: [posgrid,ebgrid],\n",
    "    1: posgrid,\n",
    "    2: ebgrid\n",
    "}\n",
    "\n",
    "labelDict = {\n",
    "    0: 'PE',\n",
    "    1: 'P',\n",
    "    2: 'E'\n",
    "}\n",
    "\n",
    "allModels = {}\n",
    "numModels = 3\n",
    "\n",
    "# get test/train indices (same for each model)\n",
    "kfoldIdx, kfoldIdx_df = g.kfoldSplit(nfolds=10)\n",
    "\n",
    "for model in range(numModels):\n",
    "    modelDict = {}\n",
    "    # get state matrix\n",
    "    stateIn = stateDict[model]\n",
    "    statemat, expr = g.squish_statemat(spiketrain, stateIn, modelType=labelDict[model])\n",
    "\n",
    "    # optimize model parameters\n",
    "    kres,train_y, test_y, train_x, test_x, train_y_raw, test_y_raw= g.kfoldOptim(kfoldIdx_df,statemat)\n",
    "\n",
    "    # check the model fit\n",
    "    testfit = g.get_testFit(kres,train_y,test_y,train_x,test_x,train_y_raw,test_y_raw)\n",
    "\n",
    "    modelDict['kfoldIdx'] = kfoldIdx_df\n",
    "    modelDict['kres'] = kres\n",
    "    modelDict['train_y'] = train_y\n",
    "    modelDict['train_x'] = train_x\n",
    "    modelDict['test_y'] = test_y\n",
    "    modelDict['test_x'] = test_x\n",
    "    modelDict['train_y_raw'] = train_y_raw\n",
    "    modelDict['test_y_raw'] = test_y_raw\n",
    "    modelDict['testfit'] = testfit\n",
    "    \n",
    "    # save in allModels dictionary\n",
    "    allModels[model] = modelDict\n",
    "\n",
    "llh, bestModel = g.findBestModel(modelDict)\n",
    "\n",
    "g.plot_llh(allModels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1);\n",
    "ax.plot(test_y[fold]); ax.plot(yhat);\n",
    "ax.set_xlabel('time step'); ax.set_ylabel('y (smoothed rate)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 2))\n",
    "_, bin_edges = np.histogram(y,120)\n",
    "ax[0].plot(bin_edges, scipy.stats.norm.pdf(bin_edges, loc=y.mean(), scale=y.std()))\n",
    "ax[0].set_title(r'Distribution of Rates')\n",
    "ax[0].set_xlabel('rate (hz)')\n",
    "ax[0].set_ylabel('hist')\n",
    "\n",
    "sns.kdeplot(y, color='#fcb103', bw=.017,shade=True)\n",
    "ax[1].set_title(r'Distribution of Rates')\n",
    "ax[1].set_xlabel('rate (hz)')\n",
    "ax[1].set_ylabel('probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualize results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(['PE', 'P', 'E'], sse);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_fit = res.x[1:]\n",
    "b_fit = res.x[0]\n",
    "y_hat = g.get_rate(X,w_fit,b_fit)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "ax.plot(y[0:10000], label='data');\n",
    "ax.plot(smooth_fr_hat_test[0:10000],label='model');\n",
    "ax.set_title(r'model vs. data')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_ylabel('rate (hz)');\n",
    "ax.legend(loc=\"upper right\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
